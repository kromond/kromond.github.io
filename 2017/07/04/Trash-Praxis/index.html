<!DOCTYPE html>
<html lang="en">
  <!-- Head tag -->
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Title -->
  
  <title>Trash Praxis - Kevin Romond</title>

  <!--Favicon-->
  <link rel="icon" href="favicon/favicon.ico">

  <!--Description-->
  
      <meta name="description" content="A collection of projects">
  

  <!--Author-->
  
      <meta name="author" content="Kevin Romond">
  

  <!-- Pure CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
  <link href="https://fonts.googleapis.com/css?family=Crimson+Text|Open+Sans:300,800" rel="stylesheet">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/css/styles.css">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->

  <!-- Google Analytics -->
  

</head>


  <body>
  	<div class="container-fluid navbar-container m-sm-5">
      <!-- Header -->
      <nav class="navbar navbar-toggleable-sm navbar-light px-1 py-3 my-3 mb-sm-5">
  <a class="navbar-brand ml-2" href="/">Kevin Romond</a>
  <button class="navbar-toggler navbar-toggler-right py-2" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse text-center" id="navbarCollapse">
    <ul class="navbar-nav ml-auto my-auto">
      
        <li class="nav-item">
          <a class="nav-link" href="/about">About</a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="/contact">Contact</a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="/blog">Blog</a>
        </li>
      
    </ul>
    <hr class="hidden-md-up" />
  </div>
</nav>


  		<div class="row">
  			<div class="col-12 mb-4">
  <img class="img-fluid project-img" src="/trashPrxisImg1.png" alt="Trash Praxis">
</div>
<div class="col-lg-4 col-12 pt-3 px-4 pr-lg-5">
  <h1>Trash Praxis</h1>
</div>
<div class="col-lg-8 col-12 pt-lg-3 mb-4 pl-lg-5 px-lg-0 px-4 portfolio-content">
  <p>The initial motivation for this project was to investigate rapid content creation using Unreal Engine 4.  The concept was to create serial VR that could be distributed either as an exectuable (like a game) or as a 360 render distributed via YouTube.  For the proof of concept a very simple framework was made: it will be like 2 person a podcast with visuals.  The podcast topic was a casual discussion of media and culture between hosts Alfio Leotta and Raqi Syed, both academics in the area of Media studies at Victoria University of Wellington.  The project was undertaken as part of the VUW ‘Digital Futures’ research initiative.</p>
<p>Producing media content for Virtual Reality head mounted displays is not particularly rapid and comes with technical challenges. There are two primary vehicles for content delivery.  One is 360 degree video.  The other is geometry and animation delivered by game engine.  Both have their drawbacks and merits both qualitatively and in terms of production issues. This project proposed to deliver in both formats providing empirical data on viable production methods for VR content by utilizing both vehicles.  Further, we are unaware of any media being generated in this manner (VR or otherwise) using motion capture virtual production techniques for an episodic talk show.</p>
<p><img src="costumeWip3.gif" alt="costume.gif"></p>
<p>‘Virtual Production’ is a filmmaking technique refined through the production of the film ‘Avatar’ whereby live action performances are captured using various technologies to be reconstructed into digital images of that performance.  This technique is being continually refined as it’s used on high budget film productions like ‘The Jungle Book’, ‘War for the Planet of the Apes’, etc.</p>
<p>By using motion capture virtual production techniques for this project we  collected an array of data around our ‘event’.  Data collected included multichannel audio, reference video, motion capture data, facial capture data all synced in time.  With this data, we can reconstruct the event with computer graphics characters and present the result in multiple formats, allowing us to gauge the result against the production effort for each format. </p>
<p><img src="CaptureYT.PNG" alt="youtubeSnip"></p>

</div>


  		</div>
  	</div>

    <!-- After footer scripts -->
    <script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>

  </body>
</html>
